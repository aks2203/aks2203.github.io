<html>
 <head>
  <title>Avi Schwarzschild</title>
  <link rel="stylesheet" href="style.css"/>
 </head>
 <body>
  <div style="font-size:36;color:#3159a9";>
    <a href="profile.png"><img src="profile_small.png" style="width:100px;height:100px;margin-bottom:-1.0em;border-radius:50%;"></a> <b>Avi Schwarzschild</b>
  </div>
  <br>
  <!-- <h1>Avi Schwarzschild</h1> -->
  <h5><em>Trying to learn about deep learning faster than deep learning can learn about me.</em></h5>
  <p>avis4k@gmail.com, [<a href="https://scholar.google.com/citations?user=WNvQ7AcAAAAJ&hl=en&authuser=1">Google Scholar</a>] [<a href="https://twitter.com/A_v_i__S">Twitter</a>] [<a href="https://github.com/aks2203">GitHub</a>] [<a href="cv.pdf">CV</a>]</p>

  <p> I am a post-doc at Carnegie Mellon University with <a href="https://zicokolter.com/">Zico Kolter</a>. My work focuses on safe and secure ML as well as reasoning in AI systems.</p>

  <p>In 2023, I finished my Ph.D. in the Applied Math and Scientific Computation program at the University of Maryland. I was advised by <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a> on my work in deep learning. My research during my PhD spanned security to generalization and more generally focused on expanding our understanding of when and why neural networks work. My specific interest in data security and model vulnerability has led to work on adversarial attacks and data poisoning. I also studied neural networks' ability to extrapolate from easy training tasks to more difficult problems at test time.</p>

  <p>From June 2022 through March 2023, I was a researcher at <a href="https://www.arthur.ai">Arthur AI</a> in New York City. And before starting at UMD, I received a master's degree in applied math at the University of Washington and a bachelor's degree in applied math at Columbia Engineering.</p>

<hr color="#7e98cc" size="4">
  <h2>Selected Papers</h2>
  <p class="pub"> Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min Chu, Gowthami Somepalli, Brian R Bartoldson, Bhavya Kailkhura, <b>Avi Schwarzschild</b>, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein. <u>NEFTune: Noisy Embeddings Improve Instruction Finetuning</u>. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2310.05914.pdf">Arxiv</a>]</p>
  <p class="pub"> Neel Jain, <b>Avi Schwarzschild</b>, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein. <u>Baseline Defenses for Adversarial Attacks Against Aligned Language Models</u> <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2309.00614.pdf">Arxiv</a>]</p>
  <p class="pub"> Randall Balestriero, Mark Ibrahim, Vlad Sobal, Ari Morcos, Shashank Shekhar, Tom Goldstein, Florian Bordes, Adrien Bardes, Gregoire Mialon, Yuandong Tian, <b>Avi Schwarzschild</b>, Andrew Gordon Wilson, Jonas Geiping, Quentin Garrido, Pierre Fernandez, Amir Bar, Hamed Pirsiavash, Yann LeCun, and Micah Goldblum. <u>A Cookbook of Self-Supervised Learning</u>. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2304.12210.pdf">ArXiv</a>]</p>
  <p class="pub"> <b>Avi Schwarzschild</b>, Max Cembalest, Karthik Rao, Keegan Hines, and John Dickerson. <u>Reckoning with the Disagreement Problem: Explanation Consensus as a Training Objective</u>. <i>Artificial Intelligence, Ethics, and Socitey</i> (<b>AIES</b>), 2023. [<a href="https://arxiv.org/pdf/2303.13299.pdf">ArXiv</a>]</p>
  <p class="pub"> Alex Stein*, <b>Avi Schwarzschild*</b>, Michael Curry, Tom Goldstein, and John Dickerson. <u>Neural Auctions Compromise Bidder Information</u>. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2303.00116.pdf">ArXiv</a>]</p>
  <p class="pub"> Arpit Bansal, Hong-Min Chu, <b>Avi Schwarzschild</b>, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, and Tom Goldstein. <u>Universal Guidance for Diffusion Models</u>. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2302.07121.pdf">ArXiv</a>]</p>
  <p class="pub"> Roman Levin, Valeriia Cherepanova, <b>Avi Schwarzschild</b>, Arpit Bansal, C Bayan Bruss, Tom Goldstein, Andrew Gordon Wilson, and Micah Goldblum. <u>Transfer Learning with Deep Tabular Models</u>. <i>International Conference on Learning Representations</i> (<b>ICLR</b>), 2023. [<a href="https://openreview.net/pdf?id=b0RuGUYo8pA">Published Version</a>]</p>
  <p class="pub"> Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, <b>Avi Schwarzschild</b>, Dawn Song, Aleksander Madry, Bo Li, and Tom Goldstein. <u>Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses</u>. <i>IEEE transactions on pattern analysis and machine intelligence</i> (<b>TPAMI</b>), 2022. [<a href="https://arxiv.org/pdf/2012.10544.pdf">ArXiv</a>][<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9743317">Published Version</a>]</p>
  <p class="pub"> Arpit Bansal*, <b>Avi Schwarzschild*</b>, Eitan Borgnia, Zeyad Emam, Furong Huang, Micah  Goldblum, and Tom Goldstein. <u>End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking</u>. <i>Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2022. [<a href="https://arxiv.org/pdf/2202.05826.pdf">ArXiv</a>]</p>
  <p class="pub"> Gowthami Somepalli, Micah Goldblum, <b>Avi Schwarzschild</b>, C Bayan Bruss, and Tom Goldstein. <u>SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training</u>. <i>Under Review</i>. [<a href="https://arxiv.org/pdf/2106.01342.pdf">ArXiv</a>]</p>
  <p class="pub"> Arpit Bansal, Micah Goldblum, Valeriia Cherepanova, <b>Avi Schwarzschild</b>, C Bayan Bruss, and Tom Goldstein. <u>MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data</u>. <i>Under Review</i>. [<a href="https://arxiv.org/pdf/2106.09643.pdf">ArXiv</a>]</p>
  <p class="pub"> <b>Avi Schwarzschild*</b>, Arjun Gupta*, Amin Ghiasi, Micah Goldblum, and Tom Goldstein. <u>The Uncanny Similarity of Recurrence and Depth</u>. <i>International Conference on Learning Representations</i> (<b>ICLR</b>), 2022. [<a href="https://openreview.net/pdf?id=3wNcr5nq56">Published Version</a>]</p>
  <p class="pub"> <b>Avi Schwarzschild</b>, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi Vishkin, Micah Goldblum, and Tom Goldstein. <u>Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks</u>. <i>Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2021. [<a href="https://arxiv.org/pdf/2106.04537.pdf">Published Version</a>]</p> 
  <p class="pub"> Micah Goldblum*, <b>Avi Schwarzschild*</b>, Ankit Patel, and Tom Goldstein. <u>Adversarial Attacks on Machine Learning Systems for High-Frequency Trading</u>. <i>International Conference on AI in Finance</i> (<b>ICAIF</b>), 2021. [<a href="https://arxiv.org/pdf/2002.09565.pdf">Published Version</a>]</p> 
  <p class="pub"> <b>Avi Schwarzschild*</b>, Micah Goldblum*, Arjun Gupta, John Dickerson, and Tom Goldstein. <u>Just How Toxic is Data Poisoning? A Benchmark for Backdoor and Data Poisoning Attacks</u>. <i>International Conference on Machine Learning</i> (<b>ICML</b>), 2021. [<a href="https://arxiv.org/pdf/2006.12557.pdf">Published Version</a>]</p> 
  <p class="pub"> Ahmed Abdelkader, Michael Curry, Liam Fowl, Tom Goldstein, <b>Avi Schwarzschild</b>, Manli Shu, Cristoph Studer, and Chen Zhu. <u>Headless Horseman: Adversarial Attacks on Transfer Learning Models</u>. <i>IEEE International Conference on Acoustics, Speech, and Signal Processing</i> (<b>ICASSP</b>), 2020. [<a href="https://arxiv.org/pdf/2004.09007.pdf">Published Version</a>]</p> 
  <p class="pub"> Micah Goldblum*, Jonas Geiping*, <b>Avi Schwarzschild</b>, Michael Moeller, and Tom Goldstein. <u>Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory</u>. <i>International Conference on Learning Representations</i> (<b>ICLR</b>), 2020. [<a href="https://openreview.net/pdf?id=HyxyIgHFvr">Published Version</a>]</p>
  <div class="banner"><em>Last updated November 2023.</em></div>
 </body>
</html>














