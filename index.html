<html>
 <head>
  <title>Avi Schwarzschild</title>
  <link rel="stylesheet" href="style.css"/>
 </head>
 <body>
  <div style="font-size:36;color:#3159a9";>
    <a href="profile.png"><img src="profile_small.png" style="width:100px;height:100px;margin-bottom:-1.0em;border-radius:50%;"></a> <b>Avi Schwarzschild</b>
  </div>
  <br>
  <!-- <h1>Avi Schwarzschild</h1> -->
  <h5><em>Trying to learn about deep learning faster than deep learning can learn about me.</em></h5>
  <p>avis4k@gmail.com, [<a href="https://scholar.google.com/citations?user=WNvQ7AcAAAAJ&hl=en&authuser=1">Google Scholar</a>] [<a href="https://twitter.com/A_v_i__S">Twitter</a>] [<a href="https://github.com/aks2203">GitHub</a>] [<a href="cv.pdf">CV</a>]</p>

  <p> I am a post-doc at Carnegie Mellon University advised by  <a href="https://zicokolter.com/">Zico Kolter</a>. My work focuses on safe and secure ML as well as reasoning in AI systems.</p>

  <p>In 2023, I finished my Ph.D. in the Applied Math and Scientific Computation program at the University of Maryland. I was advised by <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a> on my work in deep learning. My research during my PhD spanned from security to generalization and broadly focused on expanding our understanding of when and why neural networks work. My specific interest in data security and model vulnerability has led to work on adversarial attacks and data poisoning. I also studied neural networks' ability to extrapolate from easy training tasks to more difficult problems at test time.</p>

  <p>From June 2022 through March 2023, I was a researcher at <a href="https://www.arthur.ai">Arthur AI</a> in New York City. And before starting at UMD, I received a master's degree in applied math at the University of Washington and a bachelor's degree in applied math at Columbia Engineering.</p>

<hr color="#7e98cc" size="4">
  <h2>Selected Papers</h2>
  <p class="pub"> <u>NEFTune: Noisy Embeddings Improve Instruction Finetuning</u>. Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min Chu, Gowthami Somepalli, Brian R Bartoldson, Bhavya Kailkhura, <b>Avi Schwarzschild</b>, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2310.05914.pdf">Arxiv</a>]</p>
  <p class="pub"> <u>Baseline Defenses for Adversarial Attacks Against Aligned Language Models</u>. Neel Jain, <b>Avi Schwarzschild</b>, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2309.00614.pdf">Arxiv</a>]</p>
  <p class="pub"> <u>A Cookbook of Self-Supervised Learning</u>. Randall Balestriero, Mark Ibrahim, Vlad Sobal, Ari Morcos, Shashank Shekhar, Tom Goldstein, Florian Bordes, Adrien Bardes, Gregoire Mialon, Yuandong Tian, <b>Avi Schwarzschild</b>, Andrew Gordon Wilson, Jonas Geiping, Quentin Garrido, Pierre Fernandez, Amir Bar, Hamed Pirsiavash, Yann LeCun, Micah Goldblum. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2304.12210.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>Reckoning with the Disagreement Problem: Explanation Consensus as a Training Objective</u>. <b>Avi Schwarzschild</b>, Max Cembalest, Karthik Rao, Keegan Hines, John Dickerson. <i>Artificial Intelligence, Ethics, and Society (AIES)</i>, 2023. [<a href="https://arxiv.org/pdf/2303.13299.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>Neural Auctions Compromise Bidder Information</u>. Alex Stein*, <b>Avi Schwarzschild*</b>, Michael Curry, Tom Goldstein, John Dickerson. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2303.00116.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>Universal Guidance for Diffusion Models</u>. Arpit Bansal, Hong-Min Chu, <b>Avi Schwarzschild</b>, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, Tom Goldstein. <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2302.07121.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>Transfer Learning with Deep Tabular Models</u>. Roman Levin, Valeriia Cherepanova, <b>Avi Schwarzschild</b>, Arpit Bansal, C Bayan Bruss, Tom Goldstein, Andrew Gordon Wilson, Micah Goldblum. <i>International Conference on Learning Representations (ICLR)</i>, 2023. [<a href="https://openreview.net/pdf?id=b0RuGUYo8pA">Published Version</a>]</p>
  <p class="pub"> <u>Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses</u>. Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, <b>Avi Schwarzschild</b>, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2022. [<a href="https://arxiv.org/pdf/2012.10544.pdf">ArXiv</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9743317">Published Version</a>]</p>
  <p class="pub"> <u>End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking</u>. Arpit Bansal*, <b>Avi Schwarzschild*</b>, Eitan Borgnia, Zeyad Emam, Furong Huang, Micah Goldblum, Tom Goldstein. <i>Neural Information Processing Systems (NeurIPS)</i>, 2022. [<a href="https://arxiv.org/pdf/2202.05826.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training</u>. Gowthami Somepalli, Micah Goldblum, <b>Avi Schwarzschild</b>, C Bayan Bruss, Tom Goldstein. <i>Under Review</i>. [<a href="https://arxiv.org/pdf/2106.01342.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data</u>. Arpit Bansal, Micah Goldblum, Valeriia Cherepanova, <b>Avi Schwarzschild</b>, C Bayan Bruss, Tom Goldstein. <i>Under Review</i>. [<a href="https://arxiv.org/pdf/2106.09643.pdf">ArXiv</a>]</p>
  <p class="pub"> <u>The Uncanny Similarity of Recurrence and Depth</u>. <b>Avi Schwarzschild*</b>, Arjun Gupta*, Amin Ghiasi, Micah Goldblum, Tom Goldstein. <i>International Conference on Learning Representations (ICLR)</i>, 2022. [<a href="https://openreview.net/pdf?id=3wNcr5nq56">Published Version</a>]</p>
  <p class="pub"> <u>Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks</u>. <b>Avi Schwarzschild</b>, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi Vishkin, Micah Goldblum, Tom Goldstein. <i>Neural Information Processing Systems (NeurIPS)</i>, 2021. [<a href="https://arxiv.org/pdf/2106.04537.pdf">Published Version</a>]</p>
  <p class="pub"> <u>Adversarial Attacks on Machine Learning Systems for High-Frequency Trading</u>. Micah Goldblum*, <b>Avi Schwarzschild*</b>, Ankit Patel, Tom Goldstein. <i>International Conference on AI in Finance (ICAIF)</i>, 2021. [<a href="https://arxiv.org/pdf/2002.09565.pdf">Published Version</a>]</p>
  <p class="pub"> <u>Just How Toxic is Data Poisoning? A Benchmark for Backdoor and Data Poisoning Attacks</u>. <b>Avi Schwarzschild*</b>, Micah Goldblum*, Arjun Gupta, John Dickerson, Tom Goldstein. <i>International Conference on Machine Learning (ICML)</i>, 2021. [<a href="https://arxiv.org/pdf/2006.12557.pdf">Published Version</a>]</p>
  <p class="pub"> <u>Headless Horseman: Adversarial Attacks on Transfer Learning Models</u>. Ahmed Abdelkader, Michael Curry, Liam Fowl, Tom Goldstein, <b>Avi Schwarzschild</b>, Manli Shu, Cristoph Studer, Chen Zhu. <i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, 2020. [<a href="https://arxiv.org/pdf/2004.09007.pdf">Published Version</a>]</p>
  <p class="pub"> <u>Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory</u>. Micah Goldblum, Jonas Geiping, <b>Avi Schwarzschild</b>, Michael Moeller, Tom Goldstein. <i>International Conference on Learning Representations (ICLR)</i>, 2020. [<a href="https://openreview.net/pdf?id=HyxyIgHFvr">Published Version</a>]</p>

  <div class="banner"><em>Last updated November 2023.</em></div>
 </body>
</html>










