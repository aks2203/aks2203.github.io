<html>
 <head>
  <title>Avi Schwarzschild</title>
  <link rel="stylesheet" href="style.css"/>
 </head>
 <body>
    <!-- Navigation -->   
    <hr color="#7e98cc" size="4">

    <div class="nav">
        <a href="index.html">Home</a><a href="publications.html" class="active">Publications</a><a href="blog-list.html">Blog</a>
    </div>

 
    <div class="header">
      <b>Publications</b><br>
    </div> 
    <h5><em>Selected papers (complete list at <a href="https://scholar.google.com/citations?user=WNvQ7AcAAAAJ&hl=en&authuser=1">Google Scholar</a>).</em></h5>
    
    <p class="pub"> <u>Antidistillation Sampling</u> <br>
    Yash Savani*, Asher Trockman*, Zhili Feng, <b>Avi Schwarzschild</b>, Alexander Robey, Marc Finzi, J. Zico Kolter. <br>
    <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2504.13146?">Arxiv</a>]</p>
    <br style="line-height: 0px" />

    <p class="pub"> <u>Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges</u> <br>
    Nayoung Lee, Ziyang Cai, <b>Avi Schwarzschild</b>, Kangwook Lee, Dimitris Papailiopoulos.<br>
    <i>International Conference on Machine Learning (ICML)</i>, 2025. [<a href="https://arxiv.org/pdf/2502.01612">Arxiv</a>]</p>
    <br style="line-height: 0px" />

    <p class="pub"> <u>Transformers Can Do Arithmetic with the Right Embeddings</u> <br>
    Sean McLeish, Arpit Bansal, Alex Stein, Neel Jain, John Kirchenbauer, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Jonas Geiping, <b>Avi Schwarzschild</b>, Tom Goldstein. <br>
    <i>Neural Information Processing Systems (NeurIPS)</i>, 2024. [<a href="https://arxiv.org/pdf/2405.17399">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Rethinking LLM Memorization through the Lens of Adversarial Compression</u> <br>
    <b>Avi Schwarzschild*</b>, Zhili Feng*, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter. <br>
    <i>Neural Information Processing Systems (NeurIPS)</i>, 2024. [<a href="https://arxiv.org/pdf/2404.15146">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Forcing Diffuse Distributions out of Language Models</u> <br>
    Yiming Zhang, <b>Avi Schwarzschild</b>, Nicholas Carlini, J. Zico Kolter, and Daphne Ippolito. <br>
    <i>Conference on Language Modeling (COLM)</i>, 2024. [<a href="https://arxiv.org/pdf/2404.10859">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>TOFU: A Task of Fictitious Unlearning for LLMs</u> <br>
    Pratyush Maini*, Zhili Feng*, <b>Avi Schwarzschild*</b>, Zachary C. Lipton, J. Zico Kolter. <br>
    <i>Conference on Language Modeling (COLM)</i>, 2024. [<a href="https://arxiv.org/pdf/2401.06121">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text</u> <br>
    Abhimanyu Hans*, <b>Avi Schwarzschild*</b>, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein. <br>  <i>International Conference on Machine Learning (ICML)</i>, 2024. [<a href="https://arxiv.org/pdf/2401.12070">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>NEFTune: Noisy Embeddings Improve Instruction Finetuning</u> <br>
    Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min Chu, Gowthami Somepalli, Brian R. Bartoldson, Bhavya Kailkhura, <b>Avi Schwarzschild</b>, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein. <br>
    <i>International Conference on Learning Representations (ICLR)</i>, 2024. [<a href="https://arxiv.org/pdf/2310.05914.pdf">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Baseline Defenses for Adversarial Attacks Against Aligned Language Models</u> <br>
    Neel Jain, <b>Avi Schwarzschild</b>, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein. <br>
    <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2309.00614.pdf">Arxiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Transfer Learning with Deep Tabular Models</u> <br>
    Roman Levin, Valeriia Cherepanova, <b>Avi Schwarzschild</b>, Arpit Bansal, C. Bayan Bruss, Tom Goldstein, Andrew Gordon Wilson, Micah Goldblum. <br>
    <i>International Conference on Learning Representations (ICLR)</i>, 2023. [<a href="https://openreview.net/pdf?id=b0RuGUYo8pA">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses</u> <br>
    Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, <b>Avi Schwarzschild</b>, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein. <br>
    <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2022. [<a href="https://arxiv.org/pdf/2012.10544.pdf">ArXiv</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9743317">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking</u> <br>
    Arpit Bansal*, <b>Avi Schwarzschild*</b>, Eitan Borgnia, Zeyad Emam, Furong Huang, Micah Goldblum, Tom Goldstein. <br>
    <i>Neural Information Processing Systems (NeurIPS)</i>, 2022. [<a href="https://arxiv.org/pdf/2202.05826.pdf">ArXiv</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training</u> <br>
    Gowthami Somepalli, Micah Goldblum, <b>Avi Schwarzschild</b>, C. Bayan Bruss, Tom Goldstein. <br>
    <i>Preprint</i>. [<a href="https://arxiv.org/pdf/2106.01342.pdf">ArXiv</a>]</p>
    <br style="line-height: 0px" />

    <p class="pub"> <u>The Uncanny Similarity of Recurrence and Depth</u> <br>
    <b>Avi Schwarzschild*</b>, Arjun Gupta*, Amin Ghiasi, Micah Goldblum, Tom Goldstein. <br>
    <i>International Conference on Learning Representations (ICLR)</i>, 2022. [<a href="https://openreview.net/pdf?id=3wNcr5nq56">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks</u> <br>
    <b>Avi Schwarzschild</b>, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi Vishkin, Micah Goldblum, Tom Goldstein. <br>
    <i>Neural Information Processing Systems (NeurIPS)</i>, 2021. [<a href="https://arxiv.org/pdf/2106.04537.pdf">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Adversarial Attacks on Machine Learning Systems for High-Frequency Trading</u> <br>
    Micah Goldblum*, <b>Avi Schwarzschild*</b>, Ankit Patel, Tom Goldstein. <br>
    <i>International Conference on AI in Finance (ICAIF)</i>, 2021. [<a href="https://arxiv.org/pdf/2002.09565.pdf">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Just How Toxic is Data Poisoning? A Benchmark for Backdoor and Data Poisoning Attacks</u> <br>
    <b>Avi Schwarzschild*</b>, Micah Goldblum*, Arjun Gupta, John Dickerson, Tom Goldstein. <br>
    <i>International Conference on Machine Learning (ICML)</i>, 2021. [<a href="https://arxiv.org/pdf/2006.12557.pdf">Published Version</a>]</p>
    <br style="line-height: 0px" />
    
    <p class="pub"> <u>Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory</u> <br>
    Micah Goldblum, Jonas Geiping, <b>Avi Schwarzschild</b>, Michael Moeller, Tom Goldstein. <br>
    <i>International Conference on Learning Representations (ICLR)</i>, 2020. [<a href="https://openreview.net/pdf?id=HyxyIgHFvr">Published Version</a>]</p>

    <hr color="#7e98cc" size="4">
    <div class="banner"><em>Last updated June 2025.</em></div>

  </body>
</html>
<!-- File: publications.html -->